{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRACTICAL ASSIGNMENT Q 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random selected positions ::  [(48, 0), (49, 1), (37, 0), (2, 2), (7, 2), (34, 1), (4, 2), (19, 2), (3, 2), (44, 1), (38, 0), (48, 0), (18, 2), (31, 2), (3, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60.0, 68.0]     11\n",
       "(0.999, 31.0]    10\n",
       "(31.0, 60.0]      9\n",
       "(81.0, 98.0]      9\n",
       "(68.0, 81.0]      7\n",
       "Name: second, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmath import nan\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(1,100,150).reshape(50,3),columns=['first','second','third'])\n",
    "df.index.name = 'SNo.'\n",
    "\n",
    "# #initializing rows(selected randomly) with nan \n",
    "# #generating random rows value\n",
    "# random_rows = np.random.randint(0,50,5)\n",
    "# print('Random selected rows :: ',random_rows)\n",
    "\n",
    "# # initializing with nan\n",
    "# df.iloc[random_rows] = nan\n",
    "\n",
    "'''\n",
    "(i)\n",
    "'''\n",
    "\n",
    "# # counting nan values\n",
    "# print('Count of NaN values :: ',df.isna().sum().sum())\n",
    "\n",
    "'''\n",
    "=================================================================\n",
    "'''\n",
    "\n",
    "# initializing specific elements = nan by generating random row and col index value\n",
    "random_rows = np.random.randint(0,50,15)\n",
    "random_cols = np.random.randint(0,3,15)\n",
    "random_index = list(zip(random_rows,random_cols))\n",
    "print('Random selected positions :: ',random_index)\n",
    "\n",
    "# initializing value at random_index with nan\n",
    "for x,y in random_index:\n",
    "    df.iloc[x,y] = nan\n",
    "\n",
    "print('Count of NaN values :: ',df.isna().sum().sum())\n",
    "\n",
    "\n",
    "'''\n",
    "(ii)\n",
    "'''\n",
    "# count of null values in a column\n",
    "# nullCount = df.isna().sum()\n",
    "# print('Count of Nan in each column :: \\n',nullCount,'\\n')\n",
    "# indx = nullCount[nullCount>5].index\n",
    "# print('Column with count of nan > 5 :: ',list(indx),'\\n')\n",
    "# data2 = df.drop(indx,axis=1)\n",
    "# print(data2.head(5))\n",
    "\n",
    "'''\n",
    "(iii)\n",
    "'''\n",
    "\n",
    "# # finding sum of each row\n",
    "# data = df.sum(axis=1)\n",
    "\n",
    "# # finding index of the row which have max sum value\n",
    "# max_row_index = data[data == data.max()].index\n",
    "# print('Row index with max sum :: ',max_row_index)\n",
    "# # drop that row\n",
    "# display(df.drop(max_row_index))\n",
    "\n",
    "'''\n",
    "(iv)\n",
    "'''\n",
    "# display(df.sort_values('first'))\n",
    "\n",
    "'''\n",
    "(v)\n",
    "'''\n",
    "\n",
    "# display(df.drop_duplicates(subset='first',keep='first'))\n",
    "\n",
    "'''\n",
    "(vi)\n",
    "'''\n",
    "# print('Correlation between first and second column :: ')\n",
    "# df_corr = df[['first','second']].corr()\n",
    "# display(df_corr)\n",
    "\n",
    "# print('Covariance between second  and third column :: ')\n",
    "# df_cov = df[['second','third']].cov()\n",
    "# display(df_cov)\n",
    "\n",
    "\n",
    "# display(df.head(10))\n",
    "\n",
    "'''\n",
    "(viii)\n",
    "'''\n",
    "\n",
    "bins = [0,20,40,60,80,100]\n",
    "second_col_bins = pd.qcut(df['second'],5)\n",
    "second_col_bins.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(vi)\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audioop import reverse\n",
    "from re import T\n",
    "\n",
    "\n",
    "Name = ['A','B','C','D','E','F','G','H','I','J']\n",
    "\n",
    "\n",
    "#function generating roll NO.\n",
    "rollno = []\n",
    "for i in range(1,11):\n",
    "    rollno.append('AC-'+str(i))\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(40,101,50).reshape(10,5),columns = ['S1','S2','S3','S4','S5'])\n",
    "df.insert(0,'Roll No.',rollno,True)\n",
    "df.insert(1,'Name',Name,True)\n",
    "df.set_index('Roll No.',drop=True,inplace = True,)\n",
    "\n",
    "\n",
    "'''\n",
    "(i)\n",
    "'''\n",
    "\n",
    "df['AVG Marks'] = df.loc[:,'S1':'S5'].mean(axis=1)\n",
    "\n",
    "'''\n",
    "(ii)\n",
    "'''\n",
    "\n",
    "# new_row = df.mean()\n",
    "# new_row.name = 'avg'\n",
    "# df = df.append(new_row).fillna('0')\n",
    "\n",
    "'''\n",
    "(iii)\n",
    "'''\n",
    "# for i in df.columns[1:6]:\n",
    "#     print('Descriptive statistics of subject',i)\n",
    "#     display(df[i].describe())\n",
    "\n",
    "'''\n",
    "(iv)\n",
    "'''\n",
    "# DISCRETIZATION\n",
    "# bins = [0,60,70,80,90,95,100]\n",
    "# label = ['D','C','B','B+','A','A+']\n",
    "# student_grades =  pd.cut(df['AVG Marks'],bins,labels = label)\n",
    "# df['Grade'] = student_grades\n",
    "\n",
    "'''\n",
    "(v)\n",
    "'''\n",
    "# print('Frequency of each grade :: ')\n",
    "# display(df['Grade'].value_counts())\n",
    "\n",
    "\n",
    "'''\n",
    "(vi)\n",
    "'''\n",
    "# def grade(i):\n",
    "#     if i>95:\n",
    "#         return 'A+'  \n",
    "#     elif i>90:\n",
    "#         return 'A'\n",
    "#     elif i>80:\n",
    "#         return 'B'\n",
    "#     elif i>70:\n",
    "#         return 'C'\n",
    "#     elif i>60:\n",
    "#         return 'D'\n",
    "#     else:\n",
    "#         return 'E'\n",
    "\n",
    "# f = lambda x: grade(x)\n",
    "\n",
    "# assign grade for each subject\n",
    "# df.iloc[:,1:6] = df.iloc[:,1:6].applymap(f)\n",
    "# df.drop(['AVG Marks','Grade'],axis=1,inplace = True)\n",
    "\n",
    "# #function to get grade with max freq\n",
    "# f2 = lambda x : x.value_counts().idxmax()\n",
    "# df['Max Grade Obtained'] = df.iloc[:,1:6].apply(f2,axis=1)\n",
    "\n",
    "# # #funtion to get frequency of grade obtained max times\n",
    "# f3 = lambda x : x.value_counts().values[0]\n",
    "# df['Frequency'] = df.iloc[:,1:6].apply(f3,axis=1)\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hobby1 = ['Reading','Dancing','Writing','Singing','Reading','Painting']\n",
    "# hobby2 = ['Painting','Dancing','Reading','Playing','Writing','Singing']\n",
    "\n",
    "# hobby1.extend(hobby2)\n",
    "# new_series = pd.Series(hobby1).value_counts()\n",
    "# new_series.index.name = 'hobbies'\n",
    "# display(new_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRACTICE Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# df['Date'] = pd.date_range('1/1/2021',periods=10)\n",
    "# df['Temperature'] = np.random.randint(33,42,10)\n",
    "# df['Humidity'] = np.random.randint(60,81,10)\n",
    "# df['Pressure'] = np.random.randint(10,21,10)\n",
    "# df = df.set_index('Date')\n",
    "\n",
    "# display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(v)\\n'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading two csv files\n",
    "df1 = pd.read_csv('Student_2019.csv')\n",
    "df2 = pd.read_csv('Student_2020.csv' )\n",
    "\n",
    "'''\n",
    "(i)\n",
    "'''\n",
    "\n",
    "# #display all hobbies types for each course in 2019\n",
    "\n",
    "# df1_new = df1[['Course','Hobby']].drop_duplicates(keep='first')\n",
    "# df1_new = df1_new.set_index(['Course','Hobby'],drop=True)\n",
    "# df1_new = df1_new.sort_index()\n",
    "# display('Hobbies in 2019 :: ',df1_new)  \n",
    "\n",
    "\n",
    "# #display all hobbies types for each course in 2020\n",
    "# df2_new = df2[['Course','Hobby']].drop_duplicates(keep='first')\n",
    "# df2_new = df2_new.set_index(['Course','Hobby'],drop=True)\n",
    "# df2_new = df2_new.sort_index()\n",
    "# display('Hobbies in 2020 :: ',df2_new)  \n",
    "\n",
    "'''\n",
    "(ii)\n",
    "'''\n",
    "\n",
    "# print('Hobbies which are there in 2019 but not in 2020 for each course :: ')\n",
    "# df1_new = df1[['Course','Hobby']].set_index('Course',drop=True)\n",
    "# df2_new = df2[['Course','Hobby']].set_index('Course',drop=True)\n",
    "\n",
    "# for i in df1_new.index.unique():\n",
    "#     df = df1_new.loc[i]\n",
    "#     display(i,df[~df.isin(df2_new.loc[i].values.flatten())].dropna())\n",
    "\n",
    "\n",
    "'''\n",
    "(iii)\n",
    "'''\n",
    "\n",
    "# print('Hobbies which are common in both years :: ')\n",
    "# for i in df1_new.index.unique():\n",
    "#     df = df1_new.loc[i]\n",
    "#     display(df[df.isin(df2_new.loc[i].values.flatten())].dropna())\n",
    "\n",
    "'''\n",
    "(iv)\n",
    "'''\n",
    "# print('Course names in which students are exploring all hobbies in 2019 :: ')\n",
    "# for i in df1_new.index.unique():\n",
    "#     if (len(df1_new.loc[i]['Hobby'].unique())==4):\n",
    "#         print(i)\n",
    "\n",
    "# print('\\nCourse names in which students are exploring all hobbies in 2020 :: ')\n",
    "# for i in df2_new.index.unique():\n",
    "#     if (len(df2_new.loc[i]['Hobby'].unique())==4):\n",
    "#         print(i)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "(v)\n",
    "'''\n",
    "# print('Number of students exploring each hobby in 2019 :: ',len(df1['Name'].value_counts()[df1['Name'].value_counts()==4])) \n",
    "# print('Number of students exploring each hobby in 2020 :: ',len(df2['Name'].value_counts()[df2['Name'].value_counts()==4])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keshav\\AppData\\Local\\Temp\\ipykernel_2900\\4039206062.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_merged = df1.append(df2,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('StudentMarks_2019.csv')\n",
    "df2 = pd.read_csv('StudentMarks_2020.csv')\n",
    "\n",
    "'''\n",
    "(a)\n",
    "'''\n",
    "\n",
    "# remove all rows with any null value\n",
    "df1.dropna(inplace=True)\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "# drop column SNo. form both dataframes\n",
    "df1.drop('SNo.',axis=1,inplace=True)\n",
    "df2.drop('SNo.',axis=1,inplace=True)\n",
    "\n",
    "# combine dataframes\n",
    "df_merged = df1.append(df2,ignore_index=True)    \n",
    "\n",
    "\n",
    "'''\n",
    "(b)\n",
    "'''\n",
    "\n",
    "#Creating a dataframe with mean ,median and standard deviation of numeric columns\n",
    "New = df_merged.describe().iloc[[1,5,2]]\n",
    "\n",
    "# find unique values, value appearing max times and its frequency for alphanumeric columns\n",
    "alpha_num = df_merged['Roll No.'].describe()[1:]\n",
    "\n",
    "# insert alpha_num col at index 0\n",
    "New.insert(0,'Roll NO.',alpha_num.values)\n",
    "\n",
    "# assign user defined row labels to indexes\n",
    "New.index = ['unique / mean','MaxAppear / Median','Freq / Std']\n",
    "New.index.name = 'Alpha_num / Numeric'        #name of the index column\n",
    "\n",
    "\n",
    "'''\n",
    "(c)\n",
    "'''\n",
    "# storing New dataframe in a excel file\n",
    "New.to_excel('NewDF.xlsx',sheet_name='sheet1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cab0ba58926470a5a9ebf47b9a6bd95521f8f13bc9986a801c458fcdbbdf03a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
